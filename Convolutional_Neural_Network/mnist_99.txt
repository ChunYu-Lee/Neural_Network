This is the a set of hyperparameter which acheive 99% accuracy on MNIST dataset.

hyperparameters: mnist lenet5 kaiming 100 softmax 35 0.5 0.0003 0.5 0 0 0 0 0

Log level set to INFO
[INFO   ] inputDropoutRate: 0.0, hiddenDropoutRate: 0.0
[INFO   ] reading image filename './datasets/train-images-idx3-ubyte' and label filename: './datasets/train-labels-idx1-ubyte
[INFO   ] read 60000 MNIST images.
[INFO   ] reading image filename './datasets/t10k-images-idx3-ubyte' and label filename: './datasets/t10k-labels-idx1-ubyte
[INFO   ] read 10000 MNIST images.
[INFO   ] Using an SOFTMAX loss function.
[INFO   ] Starting minibatch gradient descent!
[INFO   ] minibatch (100), mnist, softmax, lr: 3.0E-4, mu:0.5
[INFO   ] calculating initial error and accuracy
[INFO   ] bestError error accuracy testingError testingAccuracy
ITERATION  230417.7291297925 230417.7291297925   13.51167 38220.55233116397  13.40000
[INFO   ] Learning rate: 2.9249999999999995E-4
  6035.267488123797 6035.267488123797   96.93333 986.3591475999572  96.94000
[INFO   ] Learning rate: 2.8518749999999996E-4
  4212.838852367166 4212.838852367166   97.78833 695.7277346273378  97.75000
[INFO   ] Learning rate: 2.7805781249999996E-4
  2678.110545877183 2678.110545877183   98.66500 495.30617082758846  98.38000
[INFO   ] Learning rate: 2.7110636718749993E-4
  2302.6420772748857 2302.6420772748857   98.83000 486.5682589363537  98.47000
[INFO   ] Learning rate: 2.643287080078124E-4
  1928.6139748118658 1928.6139748118658   99.04167 451.8621750425211  98.53000
[INFO   ] Learning rate: 2.5772049030761706E-4
  1749.0000579738294 1749.0000579738294   99.08000 427.9046032359053  98.64000
[INFO   ] Learning rate: 2.5127747804992663E-4
  1441.593936453335 1441.593936453335   99.27833 394.64217502987844  98.78000
[INFO   ] Learning rate: 2.4499554109867847E-4
  1401.7457420224557 1401.7457420224557   99.26333 417.5921475513442  98.76000
[INFO   ] Learning rate: 2.388706525712115E-4
  1119.282722475206 1119.282722475206   99.46167 343.7461044512115  98.99000
[INFO   ] Learning rate: 2.328988862569312E-4
  1119.282722475206 1191.519011148726   99.42000 387.9867049808948  98.85000
[INFO   ] Learning rate: 2.2707641410050792E-4
  1050.640436043551 1050.640436043551   99.48167 384.65963570768906  98.75000
[INFO   ] Learning rate: 2.2139950374799522E-4
  814.1977289554476 814.1977289554476   99.63833 391.24880615892084  98.80000
[INFO   ] Learning rate: 2.1586451615429532E-4
  814.1977289554476 1085.3114091312784   99.40500 408.0976244995209  98.74000
[INFO   ] Learning rate: 2.1046790325043792E-4
  661.0327451613317 661.0327451613317   99.71667 329.02239779455357  98.99000
[INFO   ] Learning rate: 2.0520620566917696E-4
  631.8998758326036 631.8998758326036   99.73167 371.90203870356805  98.84000
[INFO   ] Learning rate: 2.0007605052744753E-4
  559.7235421188532 559.7235421188532   99.80833 376.71102653689604  98.86000
[INFO   ] Learning rate: 1.9507414926426135E-4
  465.1915929522028 465.1915929522028   99.84167 350.9411342812353  98.95000
[INFO   ] Learning rate: 1.9019729553265482E-4
  463.24996523866594 463.24996523866594   99.84500 348.9444925059192  98.95000
[INFO   ] Learning rate: 1.8544236314433846E-4
  404.17204291794275 404.17204291794275   99.87667 357.3891979185955  98.90000
[INFO   ] Learning rate: 1.8080630406573E-4
  404.17204291794275 411.0221989636445   99.85833 357.7798911458528  98.97000
[INFO   ] Learning rate: 1.7628614646408673E-4
  317.5088500153574 317.5088500153574   99.92667 348.4079396325911  98.93000
[INFO   ] Learning rate: 1.7187899280248457E-4
  317.5088500153574 341.2024171964737   99.89167 370.6662607993584  98.87000
[INFO   ] Learning rate: 1.6758201798242246E-4
  290.02313611977013 290.02313611977013   99.92667 349.7232582456576  98.97000
[INFO   ] Learning rate: 1.633924675328619E-4
  289.27044048274894 289.27044048274894   99.94000 370.42648673964544  98.91000
[INFO   ] Learning rate: 1.5930765584454035E-4
  264.692881130857 264.692881130857   99.93667 355.8674940546529  98.96000
[INFO   ] Learning rate: 1.5532496444842683E-4
  234.96204741022288 234.96204741022288   99.96167 349.2389030492976  98.97000
[INFO   ] Learning rate: 1.5144184033721617E-4
  234.96204741022288 247.85899425549124   99.94167 357.11308303617244  98.95000
[INFO   ] Learning rate: 1.4765579432878575E-4
  196.40202452788927 196.40202452788927   99.96833 357.59236437949176  98.94000
[INFO   ] Learning rate: 1.4396439947056612E-4
  188.04049861402032 188.04049861402032   99.97000 354.9825505358756  99.00000
[INFO   ] Learning rate: 1.4036528948380196E-4
  173.60567685762257 173.60567685762257   99.97333 362.0681109023121  98.98000
[INFO   ] Learning rate: 1.368561572467069E-4
  170.25773614735235 170.25773614735235   99.97333 355.3638007105573  98.97000
[INFO   ] Learning rate: 1.3343475331553922E-4
  162.4669533039902 162.4669533039902   99.97500 350.17857121295606  99.05000
[INFO   ] Learning rate: 1.3009888448265074E-4
  150.47764302232846 150.47764302232846   99.97667 350.74305638242663  99.03000
[INFO   ] Learning rate: 1.2684641237058447E-4
  150.47764302232846 156.20456089790747   99.97833 356.99264706649683  99.02000
[INFO   ] Learning rate: 1.2367525206131985E-4
  145.9559808747465 145.9559808747465   99.98167 362.42903515688334  99.00000